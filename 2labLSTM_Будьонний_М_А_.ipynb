{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rX4xuDVr8Sex"
      },
      "outputs": [],
      "source": [
        "#Завантажуємо всі необхідні бібліотеки\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from tensorflow.keras.layers import Dense, LSTM, Input, Dropout, Embedding\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Виводимо датасет\n",
        "m_customers = pd.read_csv(\"Mall_Customers.csv\")\n",
        "print(m_customers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxGPKXFotK_y",
        "outputId": "18a036ec-5412-40fb-d922-7c643051fc3e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     CustomerID   Genre  Age  Annual Income (k$)  Spending Score (1-100)\n",
            "0             1    Male   19                  15                      39\n",
            "1             2    Male   21                  15                      81\n",
            "2             3  Female   20                  16                       6\n",
            "3             4  Female   23                  16                      77\n",
            "4             5  Female   31                  17                      40\n",
            "..          ...     ...  ...                 ...                     ...\n",
            "195         196  Female   35                 120                      79\n",
            "196         197  Female   45                 126                      28\n",
            "197         198    Male   32                 126                      74\n",
            "198         199    Male   32                 137                      18\n",
            "199         200    Male   30                 137                      83\n",
            "\n",
            "[200 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Обираємо потрібні поля\n",
        "m_customers['Spending Score (1-100)'] = (m_customers['Annual Income (k$)'] > 3).astype(int)\n",
        "genre = m_customers['Genre'].tolist()\n",
        "score = m_customers['Spending Score (1-100)'].tolist()\n",
        "print(m_customers.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "La4rkDgbtGH2",
        "outputId": "167ad50f-46f2-4780-e6c6-b52859c39f32"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   CustomerID   Genre  Age  Annual Income (k$)  Spending Score (1-100)\n",
            "0           1    Male   19                  15                       1\n",
            "1           2    Male   21                  15                       1\n",
            "2           3  Female   20                  16                       1\n",
            "3           4  Female   23                  16                       1\n",
            "4           5  Female   31                  17                       1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Токенізація і доповнення\n",
        "maxWordsCount = 1000\n",
        "tokenizer = Tokenizer(num_words=maxWordsCount, filters='!–\"—#$%&amp;()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\r«»', lower=True, split=' ', char_level=False)\n",
        "\n",
        "# Об'єднаємо всі текстові поля в одне, якщо потрібно\n",
        "all_text = m_customers['Genre'] + ' ' + m_customers['Age'].astype(str) + ' ' + m_customers['Annual Income (k$)'].astype(str) + ' ' + m_customers['Spending Score (1-100)'].astype(str)\n",
        "\n",
        "tokenizer.fit_on_texts(all_text)\n",
        "data = tokenizer.texts_to_sequences(all_text)\n",
        "\n",
        "max_text_len = 60\n",
        "data_pad = pad_sequences(data, maxlen=max_text_len)\n",
        "print(data_pad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mHhxMLxthbO",
        "outputId": "9662df44-ea67-4c59-8d4c-0ecf400ee0b5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  0 ...  5 55  2]\n",
            " [ 0  0  0 ... 22 55  2]\n",
            " [ 0  0  0 ... 10 56  2]\n",
            " ...\n",
            " [ 0  0  0 ...  8 80  2]\n",
            " [ 0  0  0 ...  8 81  2]\n",
            " [ 0  0  0 ... 12 81  2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Підготовка набору даних\n",
        "X = np.array(data_pad)\n",
        "Y = np.array([[1, 0] if score == 1 else [0, 1] for score in score])\n",
        "print(X, Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DefAwwkkt1s8",
        "outputId": "1decf6c0-b353-4ece-ec30-3a0cbfa74ae4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  0 ...  5 55  2]\n",
            " [ 0  0  0 ... 22 55  2]\n",
            " [ 0  0  0 ... 10 56  2]\n",
            " ...\n",
            " [ 0  0  0 ...  8 80  2]\n",
            " [ 0  0  0 ...  8 81  2]\n",
            " [ 0  0  0 ... 12 81  2]] [[1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Тренування моделі\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, Bidirectional, Conv1D, Embedding\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "# Створюємо модель\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=maxWordsCount, output_dim=128))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(64, return_sequences=False))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Компілюємо модель\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "\n",
        "# Реалізуємо ReduceLROnPlateau для налаштування швидкості навчання\n",
        "lr_reduction = ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=1, factor=0.5, min_lr=0.00001)\n",
        "\n",
        "# Навчаємо модель\n",
        "history = model.fit(X, Y, batch_size=32, epochs=40, validation_split=0.2, callbacks=[lr_reduction])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnyQLViruP-f",
        "outputId": "fd8326ff-f250-4af6-dd87-a79d8e8ed04e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "5/5 [==============================] - 5s 362ms/step - loss: 0.5779 - accuracy: 0.8687 - val_loss: 0.2634 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 2/40\n",
            "5/5 [==============================] - 1s 234ms/step - loss: 0.1230 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 3/40\n",
            "5/5 [==============================] - 1s 175ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.2975e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 4/40\n",
            "5/5 [==============================] - 1s 171ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.6564e-05 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 5/40\n",
            "5/5 [==============================] - 1s 150ms/step - loss: 6.9550e-04 - accuracy: 1.0000 - val_loss: 3.9339e-06 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 6/40\n",
            "5/5 [==============================] - 1s 155ms/step - loss: 7.0949e-04 - accuracy: 1.0000 - val_loss: 1.4305e-06 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 7/40\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.5594e-04 - accuracy: 1.0000\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "5/5 [==============================] - 1s 155ms/step - loss: 2.5594e-04 - accuracy: 1.0000 - val_loss: 7.1526e-07 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 8/40\n",
            "5/5 [==============================] - 1s 152ms/step - loss: 2.4037e-04 - accuracy: 1.0000 - val_loss: 5.9605e-07 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
            "Epoch 9/40\n",
            "5/5 [==============================] - 1s 152ms/step - loss: 2.0867e-04 - accuracy: 1.0000 - val_loss: 4.7684e-07 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
            "Epoch 10/40\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.9279e-04 - accuracy: 1.0000\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "5/5 [==============================] - 1s 154ms/step - loss: 1.9279e-04 - accuracy: 1.0000 - val_loss: 3.5763e-07 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
            "Epoch 11/40\n",
            "5/5 [==============================] - 1s 153ms/step - loss: 8.5777e-05 - accuracy: 1.0000 - val_loss: 3.5763e-07 - val_accuracy: 1.0000 - lr: 2.5000e-04\n",
            "Epoch 12/40\n",
            "5/5 [==============================] - 1s 153ms/step - loss: 8.7390e-04 - accuracy: 1.0000 - val_loss: 3.5763e-07 - val_accuracy: 1.0000 - lr: 2.5000e-04\n",
            "Epoch 13/40\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.1149e-04 - accuracy: 1.0000\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "5/5 [==============================] - 1s 148ms/step - loss: 1.1149e-04 - accuracy: 1.0000 - val_loss: 3.5763e-07 - val_accuracy: 1.0000 - lr: 2.5000e-04\n",
            "Epoch 14/40\n",
            "5/5 [==============================] - 1s 152ms/step - loss: 4.3300e-04 - accuracy: 1.0000 - val_loss: 3.5763e-07 - val_accuracy: 1.0000 - lr: 1.2500e-04\n",
            "Epoch 15/40\n",
            "5/5 [==============================] - 1s 153ms/step - loss: 1.0611e-04 - accuracy: 1.0000 - val_loss: 3.5763e-07 - val_accuracy: 1.0000 - lr: 1.2500e-04\n",
            "Epoch 16/40\n",
            "5/5 [==============================] - ETA: 0s - loss: 7.8898e-04 - accuracy: 1.0000\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "5/5 [==============================] - 1s 196ms/step - loss: 7.8898e-04 - accuracy: 1.0000 - val_loss: 3.5763e-07 - val_accuracy: 1.0000 - lr: 1.2500e-04\n",
            "Epoch 17/40\n",
            "5/5 [==============================] - 1s 214ms/step - loss: 2.2072e-04 - accuracy: 1.0000 - val_loss: 3.5763e-07 - val_accuracy: 1.0000 - lr: 6.2500e-05\n",
            "Epoch 18/40\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 4.1903e-05 - accuracy: 1.0000 - val_loss: 3.5763e-07 - val_accuracy: 1.0000 - lr: 6.2500e-05\n",
            "Epoch 19/40\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.0487e-04 - accuracy: 1.0000\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "5/5 [==============================] - 1s 153ms/step - loss: 1.0487e-04 - accuracy: 1.0000 - val_loss: 3.5763e-07 - val_accuracy: 1.0000 - lr: 6.2500e-05\n",
            "Epoch 20/40\n",
            "5/5 [==============================] - 1s 155ms/step - loss: 5.9786e-05 - accuracy: 1.0000 - val_loss: 3.5763e-07 - val_accuracy: 1.0000 - lr: 3.1250e-05\n",
            "Epoch 21/40\n",
            "5/5 [==============================] - 1s 153ms/step - loss: 8.7857e-05 - accuracy: 1.0000 - val_loss: 3.5763e-07 - val_accuracy: 1.0000 - lr: 3.1250e-05\n",
            "Epoch 22/40\n",
            "5/5 [==============================] - ETA: 0s - loss: 1.7904e-04 - accuracy: 1.0000\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 1.7904e-04 - accuracy: 1.0000 - val_loss: 3.5763e-07 - val_accuracy: 1.0000 - lr: 3.1250e-05\n",
            "Epoch 23/40\n",
            "5/5 [==============================] - 1s 153ms/step - loss: 1.1648e-04 - accuracy: 1.0000 - val_loss: 3.5763e-07 - val_accuracy: 1.0000 - lr: 1.5625e-05\n",
            "Epoch 24/40\n",
            "5/5 [==============================] - 1s 149ms/step - loss: 2.6126e-04 - accuracy: 1.0000 - val_loss: 3.5763e-07 - val_accuracy: 1.0000 - lr: 1.5625e-05\n",
            "Epoch 25/40\n",
            "5/5 [==============================] - ETA: 0s - loss: 3.1096e-04 - accuracy: 1.0000\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "5/5 [==============================] - 1s 149ms/step - loss: 3.1096e-04 - accuracy: 1.0000 - val_loss: 3.5763e-07 - val_accuracy: 1.0000 - lr: 1.5625e-05\n",
            "Epoch 26/40\n",
            "5/5 [==============================] - 1s 155ms/step - loss: 7.7862e-05 - accuracy: 1.0000 - val_loss: 3.5763e-07 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 27/40\n",
            "5/5 [==============================] - 1s 152ms/step - loss: 1.5962e-04 - accuracy: 1.0000 - val_loss: 3.5763e-07 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 28/40\n",
            "5/5 [==============================] - 1s 151ms/step - loss: 7.9892e-05 - accuracy: 1.0000 - val_loss: 3.5763e-07 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 29/40\n",
            "5/5 [==============================] - 1s 148ms/step - loss: 9.2001e-05 - accuracy: 1.0000 - val_loss: 3.5763e-07 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 30/40\n",
            "5/5 [==============================] - 1s 148ms/step - loss: 2.5381e-04 - accuracy: 1.0000 - val_loss: 3.5763e-07 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 31/40\n",
            "5/5 [==============================] - 1s 280ms/step - loss: 1.6515e-04 - accuracy: 1.0000 - val_loss: 3.5763e-07 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 32/40\n",
            "5/5 [==============================] - 1s 152ms/step - loss: 1.8506e-04 - accuracy: 1.0000 - val_loss: 3.5763e-07 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 33/40\n",
            "5/5 [==============================] - 1s 157ms/step - loss: 1.2232e-04 - accuracy: 1.0000 - val_loss: 3.5763e-07 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 34/40\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 6.3207e-04 - accuracy: 1.0000 - val_loss: 3.5763e-07 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 35/40\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 8.4844e-05 - accuracy: 1.0000 - val_loss: 3.5763e-07 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 36/40\n",
            "5/5 [==============================] - 1s 153ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 3.5763e-07 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 37/40\n",
            "5/5 [==============================] - 1s 152ms/step - loss: 2.1143e-04 - accuracy: 1.0000 - val_loss: 3.5763e-07 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 38/40\n",
            "5/5 [==============================] - 1s 148ms/step - loss: 5.6909e-05 - accuracy: 1.0000 - val_loss: 3.5763e-07 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 39/40\n",
            "5/5 [==============================] - 1s 153ms/step - loss: 1.4003e-04 - accuracy: 1.0000 - val_loss: 3.5763e-07 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
            "Epoch 40/40\n",
            "5/5 [==============================] - 1s 149ms/step - loss: 1.8251e-04 - accuracy: 1.0000 - val_loss: 3.5763e-07 - val_accuracy: 1.0000 - lr: 1.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import random\n",
        "\n",
        "def predict_random_customer(model, tokenizer, reviews, max_text_len):\n",
        "    # Виберіть випадкового клієнта\n",
        "    random_customer = random.choice(reviews)\n",
        "    print(f\"Genre: {random_customer}\")\n",
        "\n",
        "    # Попередня обробка\n",
        "    sequence = tokenizer.texts_to_sequences([random_customer])\n",
        "    padded_sequence = pad_sequences(sequence, maxlen=max_text_len)\n",
        "\n",
        "    # Передбачити стать\n",
        "    prediction = model.predict(padded_sequence)\n",
        "\n",
        "\n",
        "    print(f\"Predicted Score: {score}\")\n",
        "\n",
        "predict_random_customer(model, tokenizer, genre, max_text_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuvQybkJuy_6",
        "outputId": "0bac58d1-4fc1-4d62-a986-6dd8ee5ce957"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Genre: Male\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Predicted Score: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В ході даної роботи було створено рекурентну нейронну мережу (RNN) для семантичного аналізу тексту з використанням моделі LSTM (Long Short-Term Memory). Модель була навчена на великому корпусі текстових даних, щоб вона могла ефективно розпізнавати семантичні відтінки та контекст у введеному тексті."
      ],
      "metadata": {
        "id": "EFk-AWd3xlWr"
      }
    }
  ]
}